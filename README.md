# HMA-DER: Hierarchical Multiâ€‘Attention with Dynamic Expert Routing
> Reference PyTorch implementation for **HMAâ€‘DER**, a framework for accurate and explainable GI disease diagnosis with attention fusion (global/ROI/patch), Cognitive Alignment Score (CAS) regularization, and Dynamic Expert Routing (DER).

<p align="center">
  <img alt="HMA-DER Overview" src="https://user-images.githubusercontent.com/000000/placeholder_hma_der.png" width="75%">
</p>

---

## âœ¨ Key Features
- **Hierarchical Attention**: Stageâ€‘1 Global attention, Stageâ€‘2 ROI crossâ€‘attention, Stageâ€‘3 Patch microâ€‘attention.
- **Attention Fusion (A\*)**: Probabilistic fusion of the three attention maps with L1 normalization.
- **Explainabilityâ€‘Aware Training**: CAS alignment loss (KL + sparsity + TV) using expert/lesion masks.
- **Faithfulness Regularization**: Insertion/Deletionâ€‘style objective for attribution consistency.
- **Dynamic Expert Routing (DER)**: Mixtureâ€‘ofâ€‘experts head with entropy regularization.
- **Comprehensive Metrics**: Dice/IoU (seg), Acc/Macroâ€‘F1/AUROC + ECE/Brier (cls).
- **Fast & Modular**: Clean, minimal PyTorch codebase with Albumentations transforms.

---

## ğŸ“¦ Project Structure
```
hma_der/
â”œâ”€ configs/
â”‚  â””â”€ default.yaml
â”œâ”€ data/
â”‚  â”œâ”€ datasets.py          # Seg/Cls dataset definitions
â”‚  â””â”€ transforms.py        # Albumentations pipelines
â”œâ”€ losses/
â”‚  â”œâ”€ cas.py               # CAS alignment + sparsity + TV
â”‚  â”œâ”€ faithfulness.py      # insertion/deletion consistency
â”‚  â””â”€ routing.py           # routing entropy regularizer
â”œâ”€ metrics/
â”‚  â”œâ”€ calibration.py       # ECE & Brier
â”‚  â”œâ”€ classification.py    # Acc/F1/AUROC
â”‚  â””â”€ segmentation.py      # Dice/IoU
â”œâ”€ models/
â”‚  â”œâ”€ backbone.py          # dilated residual + tiny transformer
â”‚  â”œâ”€ attention_stages.py  # global/ROI/patch + fusion
â”‚  â”œâ”€ der.py               # gating + experts
â”‚  â””â”€ hma_der.py           # endâ€‘toâ€‘end model wrapper
â”œâ”€ utils/
â”‚  â”œâ”€ eval_utils.py        # validation loops
â”‚  â”œâ”€ train_utils.py       # AMP training
â”‚  â”œâ”€ viz.py               # heatmap overlay
â”‚  â””â”€ seed.py
â”œâ”€ train.py
â”œâ”€ evaluate.py
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸ› ï¸ Setup
```bash
# 1) create env
python -m venv .venv
source .venv/bin/activate  # on Windows: .venv\Scripts\activate

# 2) install deps
pip install -r requirements.txt
```

> Tested with Python 3.10+, PyTorch 2.2+ and CUDA 11.8/12.x.

---

## ğŸ“š Datasets & Directory Layout
Set `data_root` in `configs/default.yaml` and arrange datasets as follows:

```
data_root/
  ks/  # Kvasir-SEG (segmentation)
    images/{train,val,test}/*.png
    masks/{train,val,test}/*.png
  cvc/ # CVC-ClinicDB (segmentation)
    images/{train,val,test}/*.png
    masks/{train,val,test}/*.png
  hk/  # HyperKvasir (classification)
    images/{train,val,test}/{class_name}/*.jpg
  gv/  # GastroVision (classification)
    images/{train,val,test}/{class_name}/*.jpg
```

- **Segmentation** datasets (KS, CVC) need binary masks aligned by filename.
- **Classification** datasets (HK, GV) should have one subfolder per class under each split.

You can change input sizes per dataset in `configs/default.yaml`.

---

## ğŸš€ Training

### Segmentation (Kvasirâ€‘SEG)
```bash
python hma_der/train.py ks seg 2
```
### Segmentation (CVCâ€‘ClinicDB)
```bash
python hma_der/train.py cvc seg 2
```
### Classification (HyperKvasir)
```bash
python hma_der/train.py hk cls 8
```
### Classification (GastroVision)
```bash
python hma_der/train.py gv cls 5   # adjust class count as needed
```

Training stops early based on validation (`dice` for seg, `macro_f1` for cls). Best weights are written to
```
hma_der_{dataset}_{task}_best.pt
```

---

## âœ… Evaluation & Visualizations
Run evaluation and (optionally) save saliency overlays:
```bash
# segmentation
python hma_der/evaluate.py ks seg 2 outputs/vis_ks

# classification
python hma_der/evaluate.py hk cls 8 outputs/vis_hk
```
This prints dataset metrics and writes imageâ€‘level A\* overlays to the output directory.

---

## âš™ï¸ Configuration
All key hyperparameters live in `configs/default.yaml`:
- Optimizer/schedule (AdamW, LR, weight decay)
- Loss weights: `lambda_cls`, `lambda_align`, `lambda_faith`, `lambda_route`, `tv_strength`
- DER experts count
- Attention fusion weights `beta1/beta2/beta3`
- Perâ€‘dataset image sizes and epoch budgets
- Loader parameters (batch size, workers)

You can override these by editing the YAML or passing custom paths to `train.py`/`evaluate.py`.

---

## ğŸ§  Method Summary (Paper â†’ Code)
- **Stageâ€‘1 (Global)** â†’ `models/attention_stages.py::GlobalAttention`
- **Stageâ€‘2 (ROI)** â†’ `models/attention_stages.py::ROIAttention`
- **Stageâ€‘3 (Patch)** â†’ `models/attention_stages.py::PatchAttention`
- **Fusion (A\*)** â†’ `models/attention_stages.py::fuse_attention`
- **DER Head** â†’ `models/der.py::DynamicExpertRouting`
- **CAS Loss** â†’ `losses/cas.py::CASLoss`
- **Faithfulness** â†’ `losses/faithfulness.py::FaithfulnessLoss`
- **Routing Entropy** â†’ `losses/routing.py::RoutingEntropyLoss`

---

## ğŸ“Š Reported Metrics
- **Segmentation**: Dice, IoU (computed on A\* > 0.5 as a proxy mask), plus optional boundary metrics if you add them.
- **Classification**: Accuracy, Macroâ€‘F1, AUROC (OvR), ECE, Brier.
- **Explainability**: CAS (lower is better in our KLâ€‘based loss), Insertion/Deletion consistency (lower is better loss).

> Tip: You can export perâ€‘image CSVs of metrics by extending `utils/eval_utils.py`.

---

## ğŸ” Reproducibility Tips
- Fix `seed` in `configs/default.yaml`.
- Use the same image sizes/splits across runs.
- Log versions: `torch`, `torchvision`, GPU model, and CUDA driver.
- For crossâ€‘center transfer, train on one dataset and evaluate on another without finetuning.

---

## ğŸ§ª Extending the Code
- Swap the backbone with a larger CNN/Transformer while keeping the attention stages intact.
- Replace the ROI proposal with learned proposals (e.g., topâ€‘K via a small conv detector).
- Add boundaryâ€‘aware losses for segmentation or classâ€‘balanced CE for imbalanced classes.
- Integrate temperature scaling for postâ€‘hoc calibration.

---

## ğŸ“„ License
This project is released under the MIT License. See `LICENSE` (or include it) for details.

---

## â“ FAQ
**Q: Do I need masks for classification datasets?**  
A: No. CAS alignment is only enforced when masks are available; otherwise, the model trains with the classification loss and faithfulness regularizer.

**Q: Why do Dice/IoU use A\* as a proxy?**  
A: To evaluate attentionâ€‘asâ€‘segmentation. If you have a dedicated seg head, you can plug it in and compute metrics on its logits.

**Q: Where do I change image sizes?**  
A: `configs/default.yaml` â†’ `datasets.<name>.img_size`.
